Training hyperparameters
The following hyperparameters were used during training:

learning_rate: 7.961395091713594e-05
train_batch_size: 32
eval_batch_size: 32
seed: 27
optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
lr_scheduler_type: linear
num_epochs: 5
