---
license: apache-2.0
tags:
- generated_from_trainer
datasets:
- imagefolder
metrics:
- accuracy
model-index:
- name: swin-tiny-patch4-window7-224-finetuned-woody_90epochs
  results:
  - task:
      name: Image Classification
      type: image-classification
    dataset:
      name: imagefolder
      type: imagefolder
      config: default
      split: train
      args: default
    metrics:
    - name: Accuracy
      type: accuracy
      value: 0.8424242424242424
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# swin-tiny-patch4-window7-224-finetuned-woody_90epochs

This model is a fine-tuned version of [microsoft/swin-tiny-patch4-window7-224](https://huggingface.co/microsoft/swin-tiny-patch4-window7-224) on the imagefolder dataset.
It achieves the following results on the evaluation set:
- Loss: 0.4351
- Accuracy: 0.8424

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-05
- train_batch_size: 32
- eval_batch_size: 32
- seed: 42
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 90

### Training results

| Training Loss | Epoch | Step | Validation Loss | Accuracy |
|:-------------:|:-----:|:----:|:---------------:|:--------:|
| 0.6659        | 1.0   | 58   | 0.6216          | 0.6558   |
| 0.6181        | 2.0   | 116  | 0.5616          | 0.7115   |
| 0.5941        | 3.0   | 174  | 0.5464          | 0.7224   |
| 0.5727        | 4.0   | 232  | 0.5368          | 0.7297   |
| 0.573         | 5.0   | 290  | 0.4971          | 0.7539   |
| 0.5724        | 6.0   | 348  | 0.4920          | 0.7467   |
| 0.5584        | 7.0   | 406  | 0.4949          | 0.7564   |
| 0.5352        | 8.0   | 464  | 0.5255          | 0.7406   |
| 0.5857        | 9.0   | 522  | 0.4954          | 0.7515   |
| 0.5352        | 10.0  | 580  | 0.4888          | 0.7455   |
| 0.5161        | 11.0  | 638  | 0.5306          | 0.7224   |
| 0.5457        | 12.0  | 696  | 0.4856          | 0.76     |
| 0.5309        | 13.0  | 754  | 0.4647          | 0.7612   |
| 0.5357        | 14.0  | 812  | 0.4688          | 0.7697   |
| 0.5183        | 15.0  | 870  | 0.4830          | 0.7527   |
| 0.4837        | 16.0  | 928  | 0.5238          | 0.7370   |
| 0.51          | 17.0  | 986  | 0.4658          | 0.7745   |
| 0.533         | 18.0  | 1044 | 0.4589          | 0.7673   |
| 0.4808        | 19.0  | 1102 | 0.4375          | 0.7794   |
| 0.4854        | 20.0  | 1160 | 0.4574          | 0.7745   |
| 0.4708        | 21.0  | 1218 | 0.4738          | 0.7709   |
| 0.4801        | 22.0  | 1276 | 0.4688          | 0.76     |
| 0.4751        | 23.0  | 1334 | 0.4610          | 0.7648   |
| 0.497         | 24.0  | 1392 | 0.5058          | 0.7624   |
| 0.4767        | 25.0  | 1450 | 0.4709          | 0.7721   |
| 0.4805        | 26.0  | 1508 | 0.4447          | 0.7697   |
| 0.4557        | 27.0  | 1566 | 0.4558          | 0.7721   |
| 0.4636        | 28.0  | 1624 | 0.4325          | 0.8036   |
| 0.4285        | 29.0  | 1682 | 0.4526          | 0.7794   |
| 0.4358        | 30.0  | 1740 | 0.4302          | 0.8048   |
| 0.4257        | 31.0  | 1798 | 0.4373          | 0.7927   |
| 0.4137        | 32.0  | 1856 | 0.4458          | 0.7903   |
| 0.4389        | 33.0  | 1914 | 0.4522          | 0.7988   |
| 0.4537        | 34.0  | 1972 | 0.4395          | 0.7927   |
| 0.4249        | 35.0  | 2030 | 0.4348          | 0.8      |
| 0.4244        | 36.0  | 2088 | 0.4650          | 0.7867   |
| 0.4256        | 37.0  | 2146 | 0.4402          | 0.8012   |
| 0.4118        | 38.0  | 2204 | 0.4394          | 0.7867   |
| 0.4128        | 39.0  | 2262 | 0.4225          | 0.8133   |
| 0.416         | 40.0  | 2320 | 0.4410          | 0.8073   |
| 0.4211        | 41.0  | 2378 | 0.4464          | 0.8024   |
| 0.3838        | 42.0  | 2436 | 0.4440          | 0.7976   |
| 0.374         | 43.0  | 2494 | 0.4175          | 0.7903   |
| 0.412         | 44.0  | 2552 | 0.4169          | 0.8109   |
| 0.3746        | 45.0  | 2610 | 0.4243          | 0.8012   |
| 0.3719        | 46.0  | 2668 | 0.4132          | 0.8242   |
| 0.381         | 47.0  | 2726 | 0.4485          | 0.7988   |
| 0.3708        | 48.0  | 2784 | 0.4200          | 0.8085   |
| 0.3591        | 49.0  | 2842 | 0.4071          | 0.8279   |
| 0.3762        | 50.0  | 2900 | 0.4428          | 0.8145   |
| 0.3426        | 51.0  | 2958 | 0.4058          | 0.8158   |
| 0.3541        | 52.0  | 3016 | 0.4470          | 0.8182   |
| 0.3373        | 53.0  | 3074 | 0.4252          | 0.8194   |
| 0.3303        | 54.0  | 3132 | 0.4040          | 0.8315   |
| 0.3275        | 55.0  | 3190 | 0.4235          | 0.8291   |
| 0.3151        | 56.0  | 3248 | 0.3984          | 0.8485   |
| 0.324         | 57.0  | 3306 | 0.4283          | 0.8291   |
| 0.3276        | 58.0  | 3364 | 0.4731          | 0.8145   |
| 0.3208        | 59.0  | 3422 | 0.4360          | 0.8255   |
| 0.3355        | 60.0  | 3480 | 0.4143          | 0.8230   |
| 0.3154        | 61.0  | 3538 | 0.4234          | 0.8267   |
| 0.3451        | 62.0  | 3596 | 0.4059          | 0.8242   |
| 0.3071        | 63.0  | 3654 | 0.3991          | 0.8267   |
| 0.3303        | 64.0  | 3712 | 0.4099          | 0.8242   |
| 0.29          | 65.0  | 3770 | 0.4140          | 0.8327   |
| 0.2937        | 66.0  | 3828 | 0.4590          | 0.8218   |
| 0.3322        | 67.0  | 3886 | 0.4111          | 0.8327   |
| 0.3219        | 68.0  | 3944 | 0.4299          | 0.8327   |
| 0.2839        | 69.0  | 4002 | 0.4074          | 0.8424   |
| 0.2903        | 70.0  | 4060 | 0.4366          | 0.8315   |
| 0.2851        | 71.0  | 4118 | 0.4132          | 0.8473   |
| 0.3029        | 72.0  | 4176 | 0.4239          | 0.8473   |
| 0.2693        | 73.0  | 4234 | 0.4194          | 0.8412   |
| 0.2715        | 74.0  | 4292 | 0.4384          | 0.8412   |
| 0.2842        | 75.0  | 4350 | 0.4279          | 0.8448   |
| 0.2733        | 76.0  | 4408 | 0.4174          | 0.84     |
| 0.2694        | 77.0  | 4466 | 0.3966          | 0.8388   |
| 0.2527        | 78.0  | 4524 | 0.4194          | 0.8364   |
| 0.2813        | 79.0  | 4582 | 0.4231          | 0.8436   |
| 0.2618        | 80.0  | 4640 | 0.4494          | 0.8352   |
| 0.2639        | 81.0  | 4698 | 0.4152          | 0.8388   |
| 0.2643        | 82.0  | 4756 | 0.4241          | 0.8448   |
| 0.276         | 83.0  | 4814 | 0.4518          | 0.8327   |
| 0.2761        | 84.0  | 4872 | 0.4349          | 0.8412   |
| 0.2295        | 85.0  | 4930 | 0.4504          | 0.8315   |
| 0.2723        | 86.0  | 4988 | 0.4385          | 0.8388   |
| 0.2559        | 87.0  | 5046 | 0.4362          | 0.8473   |
| 0.2583        | 88.0  | 5104 | 0.4273          | 0.8436   |
| 0.2523        | 89.0  | 5162 | 0.4292          | 0.8424   |
| 0.2563        | 90.0  | 5220 | 0.4351          | 0.8424   |


### Framework versions

- Transformers 4.23.1
- Pytorch 1.12.1+cu113
- Datasets 2.6.1
- Tokenizers 0.13.1
