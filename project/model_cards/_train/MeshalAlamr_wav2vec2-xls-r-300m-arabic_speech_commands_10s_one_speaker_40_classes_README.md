---
license: apache-2.0
tags:
- generated_from_trainer
metrics:
- accuracy
model-index:
- name: wav2vec2-xls-r-300m-arabic_speech_commands_10s_one_speaker_40_classes
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# wav2vec2-xls-r-300m-arabic_speech_commands_10s_one_speaker_40_classes

This model is a fine-tuned version of [facebook/wav2vec2-xls-r-300m](https://huggingface.co/facebook/wav2vec2-xls-r-300m) on the None dataset.
It achieves the following results on the evaluation set:
- Loss: 1.8103
- Accuracy: 0.7671

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 0.0003
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- gradient_accumulation_steps: 4
- total_train_batch_size: 16
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 80

### Training results

| Training Loss | Epoch | Step | Validation Loss | Accuracy |
|:-------------:|:-----:|:----:|:---------------:|:--------:|
| 3.6878        | 1.0   | 25   | 3.6888          | 0.03     |
| 3.6867        | 2.0   | 50   | 3.6867          | 0.025    |
| 3.6652        | 3.0   | 75   | 3.6260          | 0.1558   |
| 3.3912        | 4.0   | 100  | 3.3953          | 0.1254   |
| 3.103         | 5.0   | 125  | 3.1497          | 0.125    |
| 2.661         | 6.0   | 150  | 2.7077          | 0.2196   |
| 2.374         | 7.0   | 175  | 2.7057          | 0.2112   |
| 1.9198        | 8.0   | 200  | 2.5269          | 0.2929   |
| 1.7809        | 9.0   | 225  | 2.8878          | 0.2204   |
| 1.4742        | 10.0  | 250  | 2.1809          | 0.3917   |
| 1.3373        | 11.0  | 275  | 1.9832          | 0.4412   |
| 1.0601        | 12.0  | 300  | 2.0539          | 0.4958   |
| 0.9018        | 13.0  | 325  | 2.2291          | 0.46     |
| 0.6925        | 14.0  | 350  | 1.5878          | 0.5946   |
| 0.6181        | 15.0  | 375  | 2.1394          | 0.5283   |
| 0.4066        | 16.0  | 400  | 2.2009          | 0.5363   |
| 0.4346        | 17.0  | 425  | 1.9644          | 0.5625   |
| 0.3882        | 18.0  | 450  | 1.3859          | 0.6658   |
| 0.3382        | 19.0  | 475  | 1.6092          | 0.6771   |
| 0.3172        | 20.0  | 500  | 1.7496          | 0.6571   |
| 0.322         | 21.0  | 525  | 1.6505          | 0.6621   |
| 0.1848        | 22.0  | 550  | 2.1235          | 0.5933   |
| 0.2695        | 23.0  | 575  | 2.1248          | 0.6054   |
| 0.2091        | 24.0  | 600  | 2.0269          | 0.6312   |
| 0.172         | 25.0  | 625  | 1.5532          | 0.7167   |
| 0.2043        | 26.0  | 650  | 1.9791          | 0.6358   |
| 0.1744        | 27.0  | 675  | 1.4877          | 0.7458   |
| 0.1837        | 28.0  | 700  | 1.8348          | 0.6896   |
| 0.2209        | 29.0  | 725  | 2.1801          | 0.6267   |
| 0.144         | 30.0  | 750  | 1.9425          | 0.6692   |
| 0.0513        | 31.0  | 775  | 1.6531          | 0.7096   |
| 0.0494        | 32.0  | 800  | 1.8506          | 0.715    |
| 0.0697        | 33.0  | 825  | 1.9599          | 0.6933   |
| 0.1528        | 34.0  | 850  | 2.0854          | 0.6521   |
| 0.0769        | 35.0  | 875  | 2.6593          | 0.6483   |
| 0.0691        | 36.0  | 900  | 1.9098          | 0.7321   |
| 0.0401        | 37.0  | 925  | 2.0541          | 0.6967   |
| 0.0287        | 38.0  | 950  | 2.3037          | 0.6904   |
| 0.1034        | 39.0  | 975  | 1.6426          | 0.7304   |
| 0.0876        | 40.0  | 1000 | 2.1685          | 0.6775   |
| 0.0557        | 41.0  | 1025 | 2.2643          | 0.6821   |
| 0.0395        | 42.0  | 1050 | 2.0308          | 0.6979   |
| 0.1046        | 43.0  | 1075 | 2.0277          | 0.7021   |
| 0.0768        | 44.0  | 1100 | 1.7130          | 0.7371   |
| 0.048         | 45.0  | 1125 | 1.9549          | 0.7192   |
| 0.0835        | 46.0  | 1150 | 1.9024          | 0.7179   |
| 0.0505        | 47.0  | 1175 | 2.0993          | 0.7125   |
| 0.0515        | 48.0  | 1200 | 1.9806          | 0.7183   |
| 0.0556        | 49.0  | 1225 | 1.8291          | 0.7321   |
| 0.0886        | 50.0  | 1250 | 2.1479          | 0.6992   |
| 0.0769        | 51.0  | 1275 | 2.0540          | 0.7146   |
| 0.0092        | 52.0  | 1300 | 1.8446          | 0.7462   |
| 0.0032        | 53.0  | 1325 | 2.0847          | 0.7125   |
| 0.0593        | 54.0  | 1350 | 1.9553          | 0.7304   |
| 0.0053        | 55.0  | 1375 | 1.8164          | 0.74     |
| 0.0101        | 56.0  | 1400 | 1.7514          | 0.7421   |
| 0.0155        | 57.0  | 1425 | 1.6395          | 0.7604   |
| 0.0035        | 58.0  | 1450 | 1.7393          | 0.7504   |
| 0.0019        | 59.0  | 1475 | 1.8103          | 0.7671   |
| 0.0144        | 60.0  | 1500 | 1.8234          | 0.7588   |
| 0.0028        | 61.0  | 1525 | 1.8479          | 0.7529   |
| 0.0306        | 62.0  | 1550 | 1.7948          | 0.7454   |
| 0.0028        | 63.0  | 1575 | 1.7417          | 0.7562   |
| 0.0095        | 64.0  | 1600 | 1.6973          | 0.7592   |
| 0.0086        | 65.0  | 1625 | 1.9997          | 0.7342   |
| 0.0953        | 66.0  | 1650 | 1.8202          | 0.7538   |
| 0.0018        | 67.0  | 1675 | 1.8316          | 0.7533   |
| 0.0053        | 68.0  | 1700 | 1.8916          | 0.7475   |
| 0.004         | 69.0  | 1725 | 1.8794          | 0.7521   |
| 0.0169        | 70.0  | 1750 | 1.8215          | 0.7533   |
| 0.0013        | 71.0  | 1775 | 1.7565          | 0.7508   |
| 0.0008        | 72.0  | 1800 | 1.8171          | 0.7454   |
| 0.0011        | 73.0  | 1825 | 1.8354          | 0.7479   |
| 0.0025        | 74.0  | 1850 | 1.8283          | 0.7488   |
| 0.0013        | 75.0  | 1875 | 1.8876          | 0.7412   |
| 0.0415        | 76.0  | 1900 | 1.8789          | 0.7454   |
| 0.0341        | 77.0  | 1925 | 1.8665          | 0.7512   |
| 0.0149        | 78.0  | 1950 | 1.8579          | 0.7488   |
| 0.0018        | 79.0  | 1975 | 1.8571          | 0.7488   |
| 0.008         | 80.0  | 2000 | 1.8596          | 0.7479   |


### Framework versions

- Transformers 4.21.1
- Pytorch 1.12.1
- Datasets 2.4.0
- Tokenizers 0.12.1
