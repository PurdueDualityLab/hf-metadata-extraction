---
license: apache-2.0
tags:
- generated_from_trainer
model-index:
- name: t5-small-entailement-Writer
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# t5-small-entailement-Writer

This model is a fine-tuned version of [t5-small](https://huggingface.co/t5-small) on the None dataset.
It achieves the following results on the evaluation set:
- Loss: 0.5958

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 32
- eval_batch_size: 32
- seed: 42
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- num_epochs: 150
- mixed_precision_training: Native AMP

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| No log        | 1.0   | 42   | 1.8511          |
| No log        | 2.0   | 84   | 1.2249          |
| No log        | 3.0   | 126  | 0.9976          |
| No log        | 4.0   | 168  | 0.9108          |
| No log        | 5.0   | 210  | 0.8478          |
| No log        | 6.0   | 252  | 0.8186          |
| No log        | 7.0   | 294  | 0.7965          |
| No log        | 8.0   | 336  | 0.7815          |
| No log        | 9.0   | 378  | 0.7634          |
| No log        | 10.0  | 420  | 0.7544          |
| No log        | 11.0  | 462  | 0.7408          |
| 1.2198        | 12.0  | 504  | 0.7298          |
| 1.2198        | 13.0  | 546  | 0.7240          |
| 1.2198        | 14.0  | 588  | 0.7139          |
| 1.2198        | 15.0  | 630  | 0.7070          |
| 1.2198        | 16.0  | 672  | 0.7028          |
| 1.2198        | 17.0  | 714  | 0.6977          |
| 1.2198        | 18.0  | 756  | 0.6926          |
| 1.2198        | 19.0  | 798  | 0.6906          |
| 1.2198        | 20.0  | 840  | 0.6846          |
| 1.2198        | 21.0  | 882  | 0.6822          |
| 1.2198        | 22.0  | 924  | 0.6760          |
| 1.2198        | 23.0  | 966  | 0.6710          |
| 0.7403        | 24.0  | 1008 | 0.6667          |
| 0.7403        | 25.0  | 1050 | 0.6657          |
| 0.7403        | 26.0  | 1092 | 0.6653          |
| 0.7403        | 27.0  | 1134 | 0.6588          |
| 0.7403        | 28.0  | 1176 | 0.6584          |
| 0.7403        | 29.0  | 1218 | 0.6573          |
| 0.7403        | 30.0  | 1260 | 0.6520          |
| 0.7403        | 31.0  | 1302 | 0.6522          |
| 0.7403        | 32.0  | 1344 | 0.6525          |
| 0.7403        | 33.0  | 1386 | 0.6463          |
| 0.7403        | 34.0  | 1428 | 0.6453          |
| 0.7403        | 35.0  | 1470 | 0.6437          |
| 0.6642        | 36.0  | 1512 | 0.6397          |
| 0.6642        | 37.0  | 1554 | 0.6382          |
| 0.6642        | 38.0  | 1596 | 0.6365          |
| 0.6642        | 39.0  | 1638 | 0.6332          |
| 0.6642        | 40.0  | 1680 | 0.6335          |
| 0.6642        | 41.0  | 1722 | 0.6325          |
| 0.6642        | 42.0  | 1764 | 0.6295          |
| 0.6642        | 43.0  | 1806 | 0.6304          |
| 0.6642        | 44.0  | 1848 | 0.6287          |
| 0.6642        | 45.0  | 1890 | 0.6272          |
| 0.6642        | 46.0  | 1932 | 0.6267          |
| 0.6642        | 47.0  | 1974 | 0.6242          |
| 0.6127        | 48.0  | 2016 | 0.6232          |
| 0.6127        | 49.0  | 2058 | 0.6225          |
| 0.6127        | 50.0  | 2100 | 0.6211          |
| 0.6127        | 51.0  | 2142 | 0.6204          |
| 0.6127        | 52.0  | 2184 | 0.6196          |
| 0.6127        | 53.0  | 2226 | 0.6183          |
| 0.6127        | 54.0  | 2268 | 0.6168          |
| 0.6127        | 55.0  | 2310 | 0.6175          |
| 0.6127        | 56.0  | 2352 | 0.6160          |
| 0.6127        | 57.0  | 2394 | 0.6154          |
| 0.6127        | 58.0  | 2436 | 0.6143          |
| 0.6127        | 59.0  | 2478 | 0.6142          |
| 0.5799        | 60.0  | 2520 | 0.6131          |
| 0.5799        | 61.0  | 2562 | 0.6122          |
| 0.5799        | 62.0  | 2604 | 0.6120          |
| 0.5799        | 63.0  | 2646 | 0.6115          |
| 0.5799        | 64.0  | 2688 | 0.6119          |
| 0.5799        | 65.0  | 2730 | 0.6112          |
| 0.5799        | 66.0  | 2772 | 0.6099          |
| 0.5799        | 67.0  | 2814 | 0.6094          |
| 0.5799        | 68.0  | 2856 | 0.6082          |
| 0.5799        | 69.0  | 2898 | 0.6092          |
| 0.5799        | 70.0  | 2940 | 0.6081          |
| 0.5799        | 71.0  | 2982 | 0.6071          |
| 0.5558        | 72.0  | 3024 | 0.6062          |
| 0.5558        | 73.0  | 3066 | 0.6079          |
| 0.5558        | 74.0  | 3108 | 0.6072          |
| 0.5558        | 75.0  | 3150 | 0.6052          |
| 0.5558        | 76.0  | 3192 | 0.6066          |
| 0.5558        | 77.0  | 3234 | 0.6049          |
| 0.5558        | 78.0  | 3276 | 0.6042          |
| 0.5558        | 79.0  | 3318 | 0.6039          |
| 0.5558        | 80.0  | 3360 | 0.6050          |
| 0.5558        | 81.0  | 3402 | 0.6042          |
| 0.5558        | 82.0  | 3444 | 0.6040          |
| 0.5558        | 83.0  | 3486 | 0.6029          |
| 0.5292        | 84.0  | 3528 | 0.6032          |
| 0.5292        | 85.0  | 3570 | 0.6039          |
| 0.5292        | 86.0  | 3612 | 0.6036          |
| 0.5292        | 87.0  | 3654 | 0.6019          |
| 0.5292        | 88.0  | 3696 | 0.6014          |
| 0.5292        | 89.0  | 3738 | 0.6022          |
| 0.5292        | 90.0  | 3780 | 0.6014          |
| 0.5292        | 91.0  | 3822 | 0.6020          |
| 0.5292        | 92.0  | 3864 | 0.6028          |
| 0.5292        | 93.0  | 3906 | 0.5994          |
| 0.5292        | 94.0  | 3948 | 0.6004          |
| 0.5292        | 95.0  | 3990 | 0.5987          |
| 0.5159        | 96.0  | 4032 | 0.5992          |
| 0.5159        | 97.0  | 4074 | 0.5993          |
| 0.5159        | 98.0  | 4116 | 0.5989          |
| 0.5159        | 99.0  | 4158 | 0.6004          |
| 0.5159        | 100.0 | 4200 | 0.6001          |
| 0.5159        | 101.0 | 4242 | 0.6008          |
| 0.5159        | 102.0 | 4284 | 0.6006          |
| 0.5159        | 103.0 | 4326 | 0.5999          |
| 0.5159        | 104.0 | 4368 | 0.5994          |
| 0.5159        | 105.0 | 4410 | 0.5996          |
| 0.5159        | 106.0 | 4452 | 0.5991          |
| 0.5159        | 107.0 | 4494 | 0.5990          |
| 0.5004        | 108.0 | 4536 | 0.5996          |
| 0.5004        | 109.0 | 4578 | 0.5988          |
| 0.5004        | 110.0 | 4620 | 0.5992          |
| 0.5004        | 111.0 | 4662 | 0.5984          |
| 0.5004        | 112.0 | 4704 | 0.5982          |
| 0.5004        | 113.0 | 4746 | 0.5973          |
| 0.5004        | 114.0 | 4788 | 0.5984          |
| 0.5004        | 115.0 | 4830 | 0.5973          |
| 0.5004        | 116.0 | 4872 | 0.5977          |
| 0.5004        | 117.0 | 4914 | 0.5970          |
| 0.5004        | 118.0 | 4956 | 0.5976          |
| 0.5004        | 119.0 | 4998 | 0.5962          |
| 0.488         | 120.0 | 5040 | 0.5969          |
| 0.488         | 121.0 | 5082 | 0.5965          |
| 0.488         | 122.0 | 5124 | 0.5969          |
| 0.488         | 123.0 | 5166 | 0.5972          |
| 0.488         | 124.0 | 5208 | 0.5966          |
| 0.488         | 125.0 | 5250 | 0.5962          |
| 0.488         | 126.0 | 5292 | 0.5966          |
| 0.488         | 127.0 | 5334 | 0.5960          |
| 0.488         | 128.0 | 5376 | 0.5969          |
| 0.488         | 129.0 | 5418 | 0.5960          |
| 0.488         | 130.0 | 5460 | 0.5960          |
| 0.483         | 131.0 | 5502 | 0.5960          |
| 0.483         | 132.0 | 5544 | 0.5965          |
| 0.483         | 133.0 | 5586 | 0.5965          |
| 0.483         | 134.0 | 5628 | 0.5963          |
| 0.483         | 135.0 | 5670 | 0.5965          |
| 0.483         | 136.0 | 5712 | 0.5962          |
| 0.483         | 137.0 | 5754 | 0.5963          |
| 0.483         | 138.0 | 5796 | 0.5961          |
| 0.483         | 139.0 | 5838 | 0.5963          |
| 0.483         | 140.0 | 5880 | 0.5964          |
| 0.483         | 141.0 | 5922 | 0.5957          |
| 0.483         | 142.0 | 5964 | 0.5957          |
| 0.4809        | 143.0 | 6006 | 0.5957          |
| 0.4809        | 144.0 | 6048 | 0.5956          |
| 0.4809        | 145.0 | 6090 | 0.5958          |
| 0.4809        | 146.0 | 6132 | 0.5958          |
| 0.4809        | 147.0 | 6174 | 0.5959          |
| 0.4809        | 148.0 | 6216 | 0.5958          |
| 0.4809        | 149.0 | 6258 | 0.5958          |
| 0.4809        | 150.0 | 6300 | 0.5958          |


### Framework versions

- Transformers 4.25.1
- Pytorch 1.13.0+cu116
- Datasets 2.7.1
- Tokenizers 0.13.2
