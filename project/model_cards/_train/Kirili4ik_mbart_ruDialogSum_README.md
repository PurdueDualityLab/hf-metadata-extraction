---
language:
- rus
tags:
- mbart
inference:
  parameters:
    no_repeat_ngram_size: 4,
    num_beams : 5
datasets:
- IlyaGusev/gazeta
- samsum
- samsum_(translated_into_Russian)
widget:
- text: | 
    –î–∂–µ—Ñ—Ñ: –ú–æ–≥—É –ª–∏ —è –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å ü§ó Transformers –Ω–∞ Amazon SageMaker? 
    –§–∏–ª–∏–ø–ø: –ö–æ–Ω–µ—á–Ω–æ, –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è HuggingFace. 
    –î–∂–µ—Ñ—Ñ: –•–æ—Ä–æ—à–æ.
    –î–∂–µ—Ñ—Ñ: –∏ –∫–∞–∫ —è –º–æ–≥—É –Ω–∞—á–∞—Ç—å? 
    –î–∂–µ—Ñ—Ñ: –≥–¥–µ —è –º–æ–≥—É –Ω–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é? 
    –§–∏–ª–∏–ø–ø: –æ–∫, –æ–∫, –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤—Å–µ: https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face

model-index:
- name: "mbart_ruDialogSum"
  results:
  - task: 
      name: Abstractive Dialogue Summarization
      type: abstractive-text-summarization 
    dataset:
      name: "SAMSum Corpus (translated to Russian)" 
      type: samsum
    metrics:
       - name: Validation ROGUE-1
         type: rogue-1
         value: 34.5
       - name: Validation ROGUE-L
         type: rogue-l
         value: 33
       - name: Test ROGUE-1
         type: rogue-1
         value: 31
       - name: Test ROGUE-L
         type: rogue-l
         value: 28
---
### üìù Description

MBart for Russian summarization fine-tuned for **dialogues** summarization.


This model was firstly fine-tuned by [Ilya Gusev](https://hf.co/IlyaGusev) on [Gazeta dataset](https://huggingface.co/datasets/IlyaGusev/gazeta). We have **fine tuned** that model on [SamSum dataset]() **translated to Russian** using GoogleTranslateAPI

ü§ó Moreover! We have implemented a **! telegram bot [@summarization_bot](https://t.me/summarization_bot) !** with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages! ¬†ü§ó


### ‚ùì How to use with code
```python
from transformers import MBartTokenizer, MBartForConditionalGeneration

# Download model and tokenizer
model_name = "Kirili4ik/mbart_ruDialogSum"   
tokenizer =  AutoTokenizer.from_pretrained(model_name)
model = MBartForConditionalGeneration.from_pretrained(model_name)
model.eval()

article_text = "..."

input_ids = tokenizer(
    [article_text],
    max_length=600,
    padding="max_length",
    truncation=True,
    return_tensors="pt",
)["input_ids"]

output_ids = model.generate(
    input_ids=input_ids,
    top_k=0,
    num_beams=3,
    no_repeat_ngram_size=3
)[0]


summary = tokenizer.decode(output_ids, skip_special_tokens=True)
print(summary)
```
