---
language:
- en
license: apache-2.0
tags:
- generated_from_trainer
datasets:
- glue
metrics:
- accuracy
model-index:
- name: bert-base-cased-sst2
  results:
  - task:
      name: Text Classification
      type: text-classification
    dataset:
      name: GLUE SST2
      type: glue
      args: sst2
    metrics:
    - name: Accuracy
      type: accuracy
      value: 0.9139908256880734
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# bert-base-cased-sst2

This model is a fine-tuned version of [bert-base-cased](https://huggingface.co/bert-base-cased) on the GLUE SST2 dataset.
It achieves the following results on the evaluation set:
- Loss: 0.2345
- Accuracy: 0.9140

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 16
- eval_batch_size: 8
- seed: 42
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_ratio: 0.06
- num_epochs: 10.0

### Training results

| Training Loss | Epoch | Step  | Validation Loss | Accuracy |
|:-------------:|:-----:|:-----:|:---------------:|:--------:|
| 0.6253        | 0.12  | 500   | 0.3641          | 0.8567   |
| 0.3189        | 0.24  | 1000  | 0.2656          | 0.8899   |
| 0.2701        | 0.36  | 1500  | 0.3463          | 0.8807   |
| 0.2533        | 0.48  | 2000  | 0.2409          | 0.9071   |
| 0.2436        | 0.59  | 2500  | 0.2345          | 0.9140   |
| 0.2155        | 0.71  | 3000  | 0.2926          | 0.9002   |
| 0.22          | 0.83  | 3500  | 0.2998          | 0.9094   |
| 0.2146        | 0.95  | 4000  | 0.2481          | 0.9140   |
| 0.1737        | 1.07  | 4500  | 0.2802          | 0.9128   |
| 0.1578        | 1.19  | 5000  | 0.3536          | 0.9083   |
| 0.1534        | 1.31  | 5500  | 0.4714          | 0.8830   |
| 0.1641        | 1.43  | 6000  | 0.3235          | 0.9128   |
| 0.1601        | 1.54  | 6500  | 0.3133          | 0.9094   |
| 0.1644        | 1.66  | 7000  | 0.3021          | 0.9071   |
| 0.1578        | 1.78  | 7500  | 0.3552          | 0.9094   |
| 0.1582        | 1.9   | 8000  | 0.2896          | 0.9106   |
| 0.1448        | 2.02  | 8500  | 0.3343          | 0.9232   |
| 0.0989        | 2.14  | 9000  | 0.3882          | 0.9048   |
| 0.1098        | 2.26  | 9500  | 0.3218          | 0.9037   |
| 0.1056        | 2.38  | 10000 | 0.3426          | 0.9140   |
| 0.112         | 2.49  | 10500 | 0.3631          | 0.9025   |
| 0.1066        | 2.61  | 11000 | 0.4084          | 0.9106   |
| 0.126         | 2.73  | 11500 | 0.3191          | 0.9117   |
| 0.12          | 2.85  | 12000 | 0.4091          | 0.9048   |
| 0.1092        | 2.97  | 12500 | 0.3602          | 0.9060   |
| 0.0826        | 3.09  | 13000 | 0.3571          | 0.9163   |
| 0.0603        | 3.21  | 13500 | 0.4021          | 0.9243   |
| 0.0636        | 3.33  | 14000 | 0.3893          | 0.9186   |
| 0.0775        | 3.44  | 14500 | 0.4373          | 0.9151   |
| 0.0842        | 3.56  | 15000 | 0.4100          | 0.9174   |
| 0.0902        | 3.68  | 15500 | 0.3878          | 0.9037   |
| 0.092         | 3.8   | 16000 | 0.3723          | 0.9140   |
| 0.0978        | 3.92  | 16500 | 0.3492          | 0.9163   |
| 0.0682        | 4.04  | 17000 | 0.4597          | 0.9209   |
| 0.0481        | 4.16  | 17500 | 0.4668          | 0.9186   |
| 0.0561        | 4.28  | 18000 | 0.4083          | 0.9209   |
| 0.0571        | 4.39  | 18500 | 0.4040          | 0.9174   |
| 0.0511        | 4.51  | 19000 | 0.4032          | 0.9197   |
| 0.062         | 4.63  | 19500 | 0.4090          | 0.9140   |
| 0.0618        | 4.75  | 20000 | 0.4150          | 0.9106   |
| 0.0599        | 4.87  | 20500 | 0.3623          | 0.9209   |
| 0.0614        | 4.99  | 21000 | 0.4421          | 0.9083   |
| 0.0385        | 5.11  | 21500 | 0.4328          | 0.9197   |
| 0.0331        | 5.23  | 22000 | 0.4569          | 0.9209   |
| 0.0343        | 5.34  | 22500 | 0.5130          | 0.9094   |
| 0.0389        | 5.46  | 23000 | 0.4741          | 0.9232   |
| 0.0413        | 5.58  | 23500 | 0.4654          | 0.9060   |
| 0.0444        | 5.7   | 24000 | 0.4888          | 0.9014   |
| 0.0406        | 5.82  | 24500 | 0.4085          | 0.9220   |
| 0.031         | 5.94  | 25000 | 0.4760          | 0.9197   |
| 0.037         | 6.06  | 25500 | 0.5403          | 0.9094   |
| 0.0239        | 6.18  | 26000 | 0.5945          | 0.9060   |
| 0.0267        | 6.29  | 26500 | 0.4595          | 0.9140   |
| 0.0338        | 6.41  | 27000 | 0.4923          | 0.9106   |
| 0.0293        | 6.53  | 27500 | 0.6128          | 0.8979   |
| 0.0253        | 6.65  | 28000 | 0.5428          | 0.9083   |
| 0.0296        | 6.77  | 28500 | 0.5244          | 0.9002   |
| 0.0279        | 6.89  | 29000 | 0.5732          | 0.9048   |
| 0.0321        | 7.01  | 29500 | 0.5824          | 0.9094   |
| 0.0179        | 7.13  | 30000 | 0.6336          | 0.9094   |
| 0.0177        | 7.24  | 30500 | 0.7145          | 0.9140   |
| 0.0262        | 7.36  | 31000 | 0.5504          | 0.9083   |
| 0.0182        | 7.48  | 31500 | 0.5924          | 0.9071   |
| 0.0187        | 7.6   | 32000 | 0.5613          | 0.9151   |
| 0.012         | 7.72  | 32500 | 0.6129          | 0.9083   |
| 0.021         | 7.84  | 33000 | 0.5698          | 0.9106   |
| 0.024         | 7.96  | 33500 | 0.6231          | 0.9083   |
| 0.0136        | 8.08  | 34000 | 0.7155          | 0.9117   |
| 0.0088        | 8.19  | 34500 | 0.7918          | 0.9060   |
| 0.0129        | 8.31  | 35000 | 0.6727          | 0.9094   |
| 0.0113        | 8.43  | 35500 | 0.6531          | 0.9117   |
| 0.0141        | 8.55  | 36000 | 0.7040          | 0.9037   |
| 0.0111        | 8.67  | 36500 | 0.6551          | 0.9094   |
| 0.0111        | 8.79  | 37000 | 0.6928          | 0.9071   |
| 0.0116        | 8.91  | 37500 | 0.6313          | 0.9094   |
| 0.0107        | 9.03  | 38000 | 0.7104          | 0.9094   |
| 0.006         | 9.14  | 38500 | 0.7446          | 0.9117   |
| 0.0048        | 9.26  | 39000 | 0.7537          | 0.9140   |
| 0.0099        | 9.38  | 39500 | 0.7715          | 0.9140   |
| 0.0067        | 9.5   | 40000 | 0.7633          | 0.9117   |
| 0.0037        | 9.62  | 40500 | 0.7669          | 0.9128   |
| 0.006         | 9.74  | 41000 | 0.7714          | 0.9128   |
| 0.0063        | 9.86  | 41500 | 0.8020          | 0.9106   |
| 0.0107        | 9.98  | 42000 | 0.7985          | 0.9117   |


### Framework versions

- Transformers 4.21.3
- Pytorch 1.7.1
- Datasets 1.18.3
- Tokenizers 0.11.6
