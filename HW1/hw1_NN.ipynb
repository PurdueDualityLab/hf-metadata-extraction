{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x: float):\n",
    "    # Logistic regression function (Sigmoid)\n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x - np.max(x))\n",
    "    return ex/ex.sum()\n",
    "\n",
    "def read_csv(path: str) -> pd.DataFrame:\n",
    "    file = pd.read_csv(path)\n",
    "    return file\n",
    "\n",
    "\n",
    "\n",
    "def feature_rep(train_set, val_set, test_set):\n",
    "    # Create feature representations for data\n",
    "    word2vec = {}\n",
    "    word_set = {}\n",
    "    word_all = []\n",
    "    idx = 0\n",
    "    # logger.debug(train_set)\n",
    "    for dataset in (train_set, val_set, test_set):\n",
    "        for text in dataset.text:\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                if word not in word2vec:\n",
    "                    word_all.append(word)\n",
    "                    word2vec[word] = idx\n",
    "                    idx += 1\n",
    "        word_set = set(word_all)\n",
    "        # logger.debug(idx)\n",
    "    # logger.info(len(word2vec))\n",
    "    # logger.info(len(word_set))\n",
    "        # print(text)\n",
    "        # break\n",
    "    return word2vec\n",
    "\n",
    "\n",
    "def text_features(dataset, embedding):\n",
    "    text_features = []\n",
    "    for text in dataset.text:\n",
    "        features = [0] * len(embedding)\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            features[embedding[word]] = 1\n",
    "        text_features.append(features)\n",
    "    # logger.info(len(text_features[0]))\n",
    "    # logger.info(len(text_features))\n",
    "    return text_features\n",
    "\n",
    "\n",
    "def data_cleaning(dataset: pd.DataFrame) -> None:\n",
    "    '''\n",
    "        Clean the duplicated entries\n",
    "    '''\n",
    "    dataset = dataset.sort_values(\"id\")\n",
    "    dataset_dup = dataset.duplicated(subset=[\"id\"])\n",
    "    index = np.where(dataset_dup==True)\n",
    "    dataset = dataset.drop(index[0])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def data_loading(epoch, num_epochs):\n",
    "    # Load raw dataset\n",
    "    TRAIN_PATH = \"./train.csv\"\n",
    "    TEST_PATH = \"./test.csv\"\n",
    "    train_set = read_csv(TRAIN_PATH)\n",
    "    test_set = read_csv(TEST_PATH)\n",
    "    \n",
    "    # data cleaning\n",
    "    train_set = data_cleaning(train_set)\n",
    "    test_set = data_cleaning(test_set)\n",
    "    # logger.info(f\"After data cleaning, len(train_set) is {len(train_set)}, len(test_set) is {len(test_set)}\")\n",
    "\n",
    "    # Cross validation\n",
    "    df_shuffle = train_set.sample(frac=1)\n",
    "    # logger.info(len(df_shuffle))\n",
    "    df_size = len(df_shuffle)\n",
    "    idx_split_left = df_size//num_epochs * (epoch)\n",
    "    idx_split_right = df_size//num_epochs * (epoch+1)\n",
    "    train_set = pd.concat([df_shuffle.iloc[:idx_split_left], df_shuffle.iloc[idx_split_right:]])\n",
    "    val_set = df_shuffle.iloc[idx_split_left:idx_split_right]\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def pre_processing(train_set: pd.DataFrame, val_set: pd.DataFrame, test_set: pd.DataFrame):\n",
    "    \n",
    "    embedding = feature_rep(train_set, val_set, test_set)\n",
    "    # Create trianing and testing inputs\n",
    "    text_features_train = text_features(train_set, embedding)\n",
    "    text_features_val = text_features(val_set, embedding)\n",
    "    text_features_test = text_features(test_set, embedding)\n",
    "    \n",
    "    # Create labels\n",
    "    emotions_train = [_ for _ in train_set.emotions]\n",
    "    emotions_val = [_ for _ in val_set.emotions]\n",
    "\n",
    "    emotion_set = set(emotions_train)\n",
    "\n",
    "    emotion2int = {emotion: i for i, emotion in enumerate(emotion_set)}\n",
    "    int2emotion = {i: emotion for i, emotion in enumerate(emotion_set)}\n",
    "    \n",
    "    emotions_train = [emotion2int[emotion] for emotion in emotions_train]\n",
    "    emotions_val = [emotion2int[emotion] for emotion in emotions_val]\n",
    "    train_targets = np.zeros((len(emotions_train), len(emotion_set)))\n",
    "    val_targets = np.zeros((len(emotions_val), len(emotion_set)))\n",
    "    for i, emotion in enumerate(emotions_train):\n",
    "        train_targets[i, emotion] = 1\n",
    "    for i, emotion in enumerate(emotions_val):\n",
    "        val_targets[i, emotion] = 1\n",
    "\n",
    "    return embedding, text_features_train, text_features_val, text_features_test,\\\n",
    "        emotion_set, train_targets, val_targets, emotion2int, int2emotion\n",
    "\n",
    "\n",
    "def post_processing(test_set, pred_emotions):\n",
    "    output = test_set.copy()\n",
    "    output['emotions'] = pred_emotions\n",
    "    output.to_csv(\"./test_lr.csv\")\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.weights = [np.random.randn(layer_sizes[i], layer_sizes[i+1]) for i in range(len(layer_sizes)-1)]\n",
    "        self.biases = [np.zeros(layer_sizes[i+1]) for i in range(len(layer_sizes)-1)]\n",
    "    \n",
    "    def layers(self):\n",
    "        return [(self.weights[i], self.biases[i]) for i in range(len(self.layer_sizes)-1)]\n",
    "    \n",
    "    def forward(self, X):\n",
    "\n",
    "        activations = [X]\n",
    "        for i in range(len(self.layer_sizes)-1):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            activation = np.maximum(0, z) # ReLU activation\n",
    "            activations.append(activation)\n",
    "        return activations\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        activations = self.forward(X)\n",
    "        d_activations = [2*(activations[-1] - y)]\n",
    "        d_weights = []\n",
    "        d_biases = []\n",
    "        for i in range(len(self.layer_sizes)-2, -1, -1):\n",
    "            d_activation = d_activations[0]\n",
    "            z = np.dot(activations[i], self.weights[i]) + self.biases[i]\n",
    "            d_z = d_activation * (z > 0).astype(float) # ReLU derivative\n",
    "            d_weight = np.dot(activations[i].T, d_z)\n",
    "            d_bias = np.sum(d_z, axis=0)\n",
    "            d_activations.insert(0, np.dot(d_z, self.weights[i].T))\n",
    "            d_weights.insert(0, d_weight)\n",
    "            d_biases.insert(0, d_bias)\n",
    "        return d_weights, d_biases\n",
    "    \n",
    "    def train(self, X, y, learning_rate=0.1, num_epochs=50):\n",
    "        for epoch in range(num_epochs):\n",
    "            # logger.debug(X)\n",
    "            # logger.debug(y)\n",
    "            d_weights, d_biases = self.backward(X, y)\n",
    "            for i in range(len(self.layer_sizes)-1):\n",
    "                self.weights[i] -= learning_rate * d_weights[i]\n",
    "                self.biases[i] -= learning_rate * d_biases[i]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        activations = self.forward(X)\n",
    "        return activations[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27383</td>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110083</td>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140764</td>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100071</td>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2837</td>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text emotions\n",
       "0   27383  i feel awful about it too because it s my job ...  sadness\n",
       "1  110083                              im alone i feel awful  sadness\n",
       "2  140764  ive probably mentioned this before but i reall...      joy\n",
       "3  100071           i was feeling a little low few days back  sadness\n",
       "4    2837  i beleive that i am much more sensitive to oth...     love"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(path: str) -> pd.DataFrame:\n",
    "    file = pd.read_csv(path)\n",
    "    return file\n",
    "\n",
    "TRAIN_SET = pd.DataFrame(read_csv(\"./train.csv\"))\n",
    "TEST_SET = pd.DataFrame(read_csv(\"./test.csv\"))\n",
    "TRAIN_SET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TRAIN_SET\n",
    "dataset_test = TEST_SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = np.array([dataset_train[\"text\"]])\n",
    "emotions_train = np.array([dataset_train[\"emotions\"]])\n",
    "\n",
    "texts_test = np.array([dataset_test[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sadness', 'sadness', 'joy', ..., 'sadness', 'surprise',\n",
       "        'sadness']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(emotions_train)\n",
    "num_labels = len(labels)\n",
    "\n",
    "one_hot = np.zeros((num_labels, num_labels), np.int8)\n",
    "np.fill_diagonal(one_hot, 1)\n",
    "\n",
    "label_dict = dict(zip(labels, one_hot))\n",
    "# logger.debug(label_dict)\n",
    "\n",
    "gt_one_hot = np.array([label_dict[label] for label in emotions_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1200)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "fold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = data_loading(fold, folds)\n",
    "embedding, text_features_train, text_features_val, _,\\\n",
    "        emotion_set, train_targets, val_targets, _, _ = pre_processing(train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [len(text_features_train[0]), 128, 64, len(emotion_set)]\n",
    "nn = NN(layer_sizes)\n",
    "# logger.debug(text_features_train[0].shape)\n",
    "# logger.debug(train_targets.shape)\n",
    "nn.train(np.array(text_features_train), train_targets, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_pred = nn.predict(text_features_val)\n",
    "\n",
    "emotions_pred_lables = np.array([labels[_] for _ in np.argmax(emotions_pred, axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(emotions_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    # Reference: https://pylessons.com/Neural-network-single-layer-part3\n",
    "    # Reference: https://towardsai.net/p/machine-learning/nothing-but-numpy-understanding-creating-neural-networks-with-computational-graphs-from-scratch-6299901091b0\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        # logger.debug(f\"W1: {self.W1.shape}\")\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        # logger.debug(f\"b1: {self.b1.shape}\")\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        # logger.debug(f\"W2: {self.W2.shape}\")\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        # logger.debug(f\"b2: {self.b2.shape}\")\n",
    "        self.scores = []\n",
    "    def forward(self, X):\n",
    "        # logger.debug(X.shape)\n",
    "        # logger.debug(self.W1.shape)\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        # logger.debug(f\"z1: {self.z1.shape}\")\n",
    "        # self.a1 = np.tanh(self.z1)\n",
    "        # Use ReLU instead\n",
    "        self.a1 = np.maximum(0, self.z1)\n",
    "        # logger.debug(self.W2.shape)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        exp_scores = np.exp(self.z2 - np.max(self.z2))\n",
    "        self.probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        return self.probs\n",
    "    \n",
    "        \n",
    "    def backward(self, X, y, y_hat, learning_rate):\n",
    "        # logger.debug(f\"X.shape={X.shape}, y.shape={y.shape}, y_hat.shape={y_hat.shape}\")\n",
    "        delta2 = y_hat\n",
    "        delta2[range(len(X)), np.argmax(y, axis=1)] -= 1\n",
    "        # logger.debug(self.W2.shape)\n",
    "        # logger.debug(self.z1.shape)\n",
    "        delta1 = delta2.dot(self.W2.T) * (1 - np.power(np.tanh(self.z1), 2))\n",
    "        \n",
    "        dW2 = np.dot(self.a1.T, delta2)\n",
    "        db2 = np.sum(delta2, axis=0, keepdims=True)\n",
    "        dW1 = np.dot(X.T, delta1)\n",
    "        db1 = np.sum(delta1, axis=0)\n",
    "\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "\n",
    "    def train(self, X, y, val_targets, text_features_val, num_epochs, learning_rate):\n",
    "        for epoch in range(num_epochs):\n",
    "            # forward pass\n",
    "            y_hat = self.forward(X)\n",
    "            # calculate the loss\n",
    "            correct_logprobs = -np.log(y_hat[range(len(X)), np.argmax(y, axis=1)]+1e-12)\n",
    "            data_loss = np.sum(correct_logprobs) / len(X)\n",
    "            # print the loss every 100 epochs\n",
    "            \n",
    "\n",
    "                # self.scores.append(score)\n",
    "            # backward pass\n",
    "            # logger.debug(X.shape)\n",
    "            # logger.debug(y.shape)\n",
    "            self.backward(X, y, y_hat, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                pred_val = self.predict(text_features_val)\n",
    "                score = np.mean(np.argmax(pred_val, axis=1) == np.argmax(val_targets, axis=1))\n",
    "                self.scores.append(score)\n",
    "                logger.info(f\"Epoch: {epoch}, loss: {data_loss}, accuracy: {score * 100:.2f}%.\")\n",
    "\n",
    "            # eval\n",
    "\n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        # forward pass\n",
    "        y_hat = self.forward(X)\n",
    "        # return the index with highest probability\n",
    "        # logger.debug(y_hat.shape)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "\n",
    "    def get_scores(self):\n",
    "        return self.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 4892)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 21:05:49.575 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:05:49.576 | INFO     | __main__:train:64 - Epoch: 0, loss: 1.7922428393391725, accuracy: 32.22%.\n",
      "2023-03-01 21:05:55.437 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:05:55.438 | INFO     | __main__:train:64 - Epoch: 100, loss: 1.0703252540600117, accuracy: 34.73%.\n",
      "2023-03-01 21:06:00.149 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:00.149 | INFO     | __main__:train:64 - Epoch: 200, loss: 0.19645095463366796, accuracy: 48.54%.\n",
      "2023-03-01 21:06:04.887 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:04.888 | INFO     | __main__:train:64 - Epoch: 300, loss: 0.04073902297749522, accuracy: 47.70%.\n",
      "2023-03-01 21:06:09.656 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:09.657 | INFO     | __main__:train:64 - Epoch: 400, loss: 0.0187829648142546, accuracy: 49.37%.\n",
      "2023-03-01 21:06:14.708 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:14.709 | INFO     | __main__:train:64 - Epoch: 500, loss: 0.011686389913862665, accuracy: 49.37%.\n",
      "2023-03-01 21:06:19.491 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:19.492 | INFO     | __main__:train:64 - Epoch: 600, loss: 0.008325083789048938, accuracy: 49.79%.\n",
      "2023-03-01 21:06:24.262 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:24.263 | INFO     | __main__:train:64 - Epoch: 700, loss: 0.00640456013857511, accuracy: 49.79%.\n",
      "2023-03-01 21:06:29.024 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:29.025 | INFO     | __main__:train:64 - Epoch: 800, loss: 0.005177880645057371, accuracy: 49.79%.\n",
      "2023-03-01 21:06:33.765 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:33.766 | INFO     | __main__:train:64 - Epoch: 900, loss: 0.004332396683127551, accuracy: 50.21%.\n",
      "2023-03-01 21:06:38.556 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:38.557 | INFO     | __main__:train:64 - Epoch: 1000, loss: 0.0037172352749611417, accuracy: 50.63%.\n",
      "2023-03-01 21:06:43.418 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:43.419 | INFO     | __main__:train:64 - Epoch: 1100, loss: 0.0032500703454401815, accuracy: 51.05%.\n",
      "2023-03-01 21:06:48.216 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:48.217 | INFO     | __main__:train:64 - Epoch: 1200, loss: 0.0028837466844792046, accuracy: 51.05%.\n",
      "2023-03-01 21:06:53.098 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:53.099 | INFO     | __main__:train:64 - Epoch: 1300, loss: 0.0025891179564026005, accuracy: 51.05%.\n",
      "2023-03-01 21:06:57.930 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:06:57.931 | INFO     | __main__:train:64 - Epoch: 1400, loss: 0.0023472968001829724, accuracy: 51.05%.\n",
      "2023-03-01 21:07:02.719 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:07:02.720 | INFO     | __main__:train:64 - Epoch: 1500, loss: 0.002145190549834713, accuracy: 51.05%.\n",
      "2023-03-01 21:07:08.976 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:07:08.977 | INFO     | __main__:train:64 - Epoch: 1600, loss: 0.001973763657903159, accuracy: 51.05%.\n",
      "2023-03-01 21:07:15.470 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:07:15.471 | INFO     | __main__:train:64 - Epoch: 1700, loss: 0.0018267033300049197, accuracy: 51.05%.\n",
      "2023-03-01 21:07:21.184 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:07:21.185 | INFO     | __main__:train:64 - Epoch: 1800, loss: 0.0016991951740893828, accuracy: 51.46%.\n",
      "2023-03-01 21:07:26.685 | DEBUG    | __main__:predict:74 - (239, 6)\n",
      "2023-03-01 21:07:26.686 | INFO     | __main__:train:64 - Epoch: 1900, loss: 0.0015876134409162812, accuracy: 51.46%.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"./train.csv\"\n",
    "    TEST_PATH = \"./test.csv\"\n",
    "    train_set = read_csv(TRAIN_PATH)\n",
    "    test_set = read_csv(TEST_PATH)\n",
    "    val_set = read_csv(TRAIN_PATH)\n",
    "    train_set = data_cleaning(train_set)\n",
    "    val_set = data_cleaning(val_set)\n",
    "    test_set = data_cleaning(test_set)\n",
    "    embedding, _, _, text_features_test,\\\n",
    "            emotion_set, _, _, emotion2int, int2emotion = pre_processing(train_set, val_set, test_set)\n",
    "    \n",
    "    folds = 5\n",
    "    scores = []\n",
    "    best_score = 0\n",
    "    for fold in range(folds):\n",
    "        train_set, val_set, test_set = data_loading(fold, folds)\n",
    "        _, text_features_train, text_features_val, _,\\\n",
    "                _, train_targets, val_targets, _, _ = pre_processing(train_set, val_set, test_set)\n",
    "        weights = np.zeros((len(embedding), len(emotion_set)))\n",
    "        if fold == 0:\n",
    "            logger.info(f\"Input size = {np.array(text_features_train).shape}\")\n",
    "        text_features_train = np.array(text_features_train)\n",
    "        train_targets = np.array(train_targets)\n",
    "        text_features_val = np.array(text_features_val)\n",
    "        val_targets = np.array(val_targets)\n",
    "        X = np.array(text_features_train)\n",
    "        y = np.array(train_targets)\n",
    "        # create a neural network with 100 hidden units\n",
    "        nn = NeuralNetwork(len(text_features_train[0]), 120, len(emotion_set))\\\n",
    "\n",
    "        # train the neural network\n",
    "        num_epochs = 2000\n",
    "        lr = 0.001\n",
    "        nn.train(X, y, val_targets, text_features_val, num_epochs=num_epochs, learning_rate=lr)\n",
    "\n",
    "        scores_fold = nn.get_scores()\n",
    "        scores.append(scores_fold)\n",
    "        if scores_fold[-1] > best_score:\n",
    "            best_nn = nn\n",
    "            best_score = scores_fold[-1]\n",
    "        logger.info(f\"Best Accuracy = {best_score * 100:.2f}%\")\n",
    "        # break\n",
    "    for score in scores:\n",
    "        plt.plot(np.arange(len(score)), score)\n",
    "    plt.title(f\"NN: {folds}-fold Cross Validation, lr={lr}, epochs={num_epochs}, acc={best_score}\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.savefig(f\"NN_highestAcc={best_score}_{folds}-fold Cross Validation_lr={lr}_epochs={num_epochs}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32217573221757323,\n",
       " 0.34309623430962344,\n",
       " 0.4895397489539749,\n",
       " 0.4560669456066946,\n",
       " 0.4769874476987448,\n",
       " 0.4769874476987448,\n",
       " 0.4895397489539749,\n",
       " 0.48535564853556484,\n",
       " 0.48535564853556484,\n",
       " 0.4811715481171548,\n",
       " 0.4895397489539749,\n",
       " 0.4895397489539749,\n",
       " 0.49372384937238495,\n",
       " 0.497907949790795,\n",
       " 0.497907949790795,\n",
       " 0.497907949790795,\n",
       " 0.497907949790795,\n",
       " 0.497907949790795,\n",
       " 0.497907949790795,\n",
       " 0.497907949790795]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = nn.get_scores()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Validation Accuracy')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "# plt.title(f\"{folds}-fold Cross Validation, lr={lr}, epochs={num_epochs}, highest acc={nn.scores}\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.savefig(f\"LR_highestAcc={scores}_{folds}-fold Cross Validation_lr={learning_rate}_lambda={reg_lambda}_iteration={num_iters}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./train.csv\"\n",
    "TEST_PATH = \"./test.csv\"\n",
    "train_set = read_csv(TRAIN_PATH)\n",
    "test_set = read_csv(TEST_PATH)\n",
    "val_set = read_csv(TRAIN_PATH)\n",
    "train_set = data_cleaning(train_set)\n",
    "val_set = data_cleaning(val_set)\n",
    "test_set = data_cleaning(test_set)\n",
    "embedding, _, _, text_features_test,\\\n",
    "        emotion_set, _, _, emotion2int, int2emotion = pre_processing(train_set, val_set, test_set)\n",
    "\n",
    "folds = 5\n",
    "scores = []\n",
    "best_score = 0\n",
    "for fold in range(folds):\n",
    "        train_set, val_set, test_set = data_loading(fold, folds)\n",
    "        _, text_features_train, text_features_val, _,\\\n",
    "                _, train_targets, val_targets, _, _ = pre_processing(train_set, val_set, test_set)\n",
    "        weights = np.zeros((len(embedding), len(emotion_set)))\n",
    "        if fold == 0:\n",
    "                logger.info(f\"Input size = {np.array(text_features_train).shape}\")\n",
    "        text_features_train = np.array(text_features_train)\n",
    "        train_targets = np.array(train_targets)\n",
    "        text_features_val = np.array(text_features_val)\n",
    "        val_targets = np.array(val_targets)\n",
    "        X = np.array(text_features_train)\n",
    "        y = np.array(train_targets)\n",
    "        # create a neural network with 100 hidden units\n",
    "        nn = NeuralNetwork(len(text_features_train[0]), 120, len(emotion_set))\n",
    "        # train the neural network\n",
    "        num_epochs = 2000\n",
    "        lr = 0.001\n",
    "        nn.train(X, y, val_targets, text_features_val, num_epochs=num_epochs, learning_rate=lr)\n",
    "\n",
    "        scores_fold = nn.get_scores()\n",
    "        scores.append(scores_fold)\n",
    "        if scores_fold[-1] > best_score:\n",
    "                best_nn = nn\n",
    "                best_score = scores_fold[-1]\n",
    "        logger.info(f\"Best Accuracy = {best_score * 100:.2f}%\")\n",
    "        # break\n",
    "for score in scores:\n",
    "        plt.plot(np.arange(len(score)), score)\n",
    "        plt.title(f\"NN: {folds}-fold Cross Validation, lr={lr}, epochs={num_epochs}, acc={best_score}\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Validation Accuracy\")\n",
    "        plt.savefig(f\"NN_highestAcc={best_score}_{folds}-fold Cross Validation_lr={lr}_epochs={num_epochs}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
